{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Understand & perform basic Text preprocessing technique and extering meaningful info from it\n"
      ],
      "metadata": {
        "id": "s6iAkBZbCyp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Tokenization"
      ],
      "metadata": {
        "id": "tX5afzBjA3kT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rcb71ttAylC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493f8c53-e84d-44a7-a331-960d57e02621"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Virat', 'Kohli', 'is', 'great', '#cricketer']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "## Splitting sentences\n",
        "import nltk\n",
        "data = \"Virat Kohli is great #cricketer\"\n",
        "data.split()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5OE-Ic2Rpj2",
        "outputId": "c3bf1c5a-df23-43c1-b15f-a0348e5f0d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Splitting sentences in the paragraph\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "text = \"Hello everyone. I’m student of guni, I like to guni campus\"\n",
        "sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa6H8gqGED7R",
        "outputId": "cba8a063-5880-4fc8-8555-b4b6d6a97e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello everyone.', 'I’m student of guni, I like to guni campus']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Splitting words in a sentence\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"I’m student of guni.\"\n",
        "word_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyA0aYy7NSxJ",
        "outputId": "71fb3e6a-08f4-457c-fe10-4f1f44e3512c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', '’', 'm', 'student', 'of', 'guni', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regular-Expression Tokenizers"
      ],
      "metadata": {
        "id": "a7dqidr2Et8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "metadata": {
        "id": "runLmmNpEQ2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Good muffins cost $3.88\\nin New York.  Please buy me\\ntwo of them.\\n\\nThanks.\"\n",
        "tokenizer = RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\S+')\n",
        "tokenizer.tokenize(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wciIsTinE1Kr",
        "outputId": "aeb85553-4825-4463-b250-f168c02e142a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Good',\n",
              " 'muffins',\n",
              " 'cost',\n",
              " '$3.88',\n",
              " 'in',\n",
              " 'New',\n",
              " 'York',\n",
              " '.',\n",
              " 'Please',\n",
              " 'buy',\n",
              " 'me',\n",
              " 'two',\n",
              " 'of',\n",
              " 'them',\n",
              " '.',\n",
              " 'Thanks',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "s = \"We'll - A Rolex watch costs in the range of $3000.0 - $8000.0 in USA.\"\n",
        "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
        "tokenizer.tokenize(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph9wGIg1FMjp",
        "outputId": "bf6fb9f5-d907-4b66-ea78-2a96bac41ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We',\n",
              " \"'ll\",\n",
              " '-',\n",
              " 'A',\n",
              " 'Rolex',\n",
              " 'watch',\n",
              " 'costs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'range',\n",
              " 'of',\n",
              " '$3000.0',\n",
              " '-',\n",
              " '$8000.0',\n",
              " 'in',\n",
              " 'USA',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blank line tokenizer"
      ],
      "metadata": {
        "id": "5TOoNpP_JEYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import BlanklineTokenizer\n",
        "a = \"My name is Rajan\\n\\nI am 6th sem student of U.V Patel college\"\n",
        "BlanklineTokenizer().tokenize(a)"
      ],
      "metadata": {
        "id": "QUbThM9uJGVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efaa2980-1531-4a5e-d94f-943fd8ad22ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My name is Rajan', 'I am 6th sem student of U.V Patel college']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word punctuation tokenization"
      ],
      "metadata": {
        "id": "LLzOUgBGIkqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "a2 = \"I have Iphone 14 pro max cost of ₹1,35,490.\"\n",
        "wordpunct_tokenize(a2)"
      ],
      "metadata": {
        "id": "DAY2jlaxLN_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf650533-2358-4678-80b5-06b8ee1384a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'have',\n",
              " 'Iphone',\n",
              " '14',\n",
              " 'pro',\n",
              " 'max',\n",
              " 'cost',\n",
              " 'of',\n",
              " '₹',\n",
              " '1',\n",
              " ',',\n",
              " '35',\n",
              " ',',\n",
              " '490',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "sCYOFJl1Mnnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "a3 = \"I does't want to go USA.\"\n",
        "TreebankWordTokenizer().tokenize(a3)"
      ],
      "metadata": {
        "id": "uOFsGrD8Mozc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe95d4e-66fd-401c-c848-c10a9314d25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', \"does't\", 'want', 'to', 'go', 'USA', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tweet Tokenizer"
      ],
      "metadata": {
        "id": "pxl4x72ZOo3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "twt = \"Hi:), {Good Afternoon}\"\n",
        "TweetTokenizer().tokenize(twt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5ynOio4eBGU",
        "outputId": "f21b04fd-967f-47fb-b565-19c6d58e694b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi', ':)', ',', '{', 'Good', 'Afternoon', '}']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a4 = \"I does't want to go USA:).\"\n",
        "print(tokenizer.tokenize(a4))\n",
        "print(wordpunct_tokenize(a4))\n",
        "print(TreebankWordTokenizer().tokenize(a4))\n",
        "print(TweetTokenizer().tokenize(a4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me0FP8JHM7Bv",
        "outputId": "462433bb-0484-471b-d55b-d5e546d300aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'does', \"'t\", 'want', 'to', 'go', 'USA', ':).']\n",
            "['I', 'does', \"'\", 't', 'want', 'to', 'go', 'USA', ':).']\n",
            "['I', \"does't\", 'want', 'to', 'go', 'USA', ':', ')', '.']\n",
            "['I', \"does't\", 'want', 'to', 'go', 'USA', ':)', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Porter Stemmer\n"
      ],
      "metadata": {
        "id": "OW8WlX4YBr9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "plurals = ['caresses', 'flies', 'dies', 'mules', 'died', 'agreed', 'owned', 'humbled', 'sized', 'meeting', 'stating',\n",
        "           'siezing', 'itemization', 'traditional', 'reference', 'colonizer', 'plotted', 'having', 'generously']\n",
        "singles = [stemmer.stem(plural) for plural in plurals]\n",
        "print(' '.join(singles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaVomRAmBw5R",
        "outputId": "950abcc6-dca1-4008-c560-f6d0cd68ee61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caress fli die mule die agre own humbl size meet state siez item tradit refer colon plot have gener\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Snowball Stemmer"
      ],
      "metadata": {
        "id": "2sY2wjCoD3kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "plurals = ['caresses', 'flies', 'dies', 'mules', 'died', 'agreed', 'owned', 'humbled', 'sized', 'meeting', 'stating',\n",
        "           'siezing', 'itemization', 'traditional', 'reference', 'colonizer', 'plotted', 'having', 'generously']\n",
        "singles = [stemmer.stem(plural) for plural in plurals]\n",
        "print(' '.join(singles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsSA9dkgDfEf",
        "outputId": "9b16413e-ca7d-4588-d3b4-03a988bbe8c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caress fli die mule die agre own humbl size meet state siez item tradit refer colon plot have generous\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "print(SnowballStemmer.languages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2wDn6r7E7Gi",
        "outputId": "c833bcc0-4e70-4cbf-8d5f-5933248b4ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "print(SnowballStemmer.languages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDTZrvU9GVvf",
        "outputId": "2f13381f-765b-4043-9c1a-a40fdb24fbba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer2 = SnowballStemmer(language='english')\n",
        "singles = [stemmer2.stem(plural) for plural in plurals]\n",
        "print(' '.join(singles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFkGFSf5GWbp",
        "outputId": "60c89dd6-6cb9-499e-dcbd-b16c72b3c325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caress fli die mule die agre own humbl size meet state siez item tradit refer colon plot have generous\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WordNet\n"
      ],
      "metadata": {
        "id": "hVcnx976hY48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"wordnet\")\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDdAt3KxglAR",
        "outputId": "4d84b54b-8c5a-4f08-b330-752d3db77a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "s = \"We are putting in efforts to enhance our understanding of Lemmatization\"\n",
        "token_list = s.split()\n",
        "print(\"The tokens are: \", token_list)\n",
        "lemmatized_output = ' '.join([lemmatizer.lemmatize(token) for token in token_list])\n",
        "print(\"The lemmatized output is: \", lemmatized_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgcaLJDihd_J",
        "outputId": "fab00a5c-cb51-4f1f-c6fb-614bb285ee55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tokens are:  ['We', 'are', 'putting', 'in', 'efforts', 'to', 'enhance', 'our', 'understanding', 'of', 'Lemmatization']\n",
            "The lemmatized output is:  We are putting in effort to enhance our understanding of Lemmatization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## stopwords"
      ],
      "metadata": {
        "id": "J1iRRLZ-HpH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = set(stopwords.words('english'))\n",
        "\", \".join(stop)"
      ],
      "metadata": {
        "id": "pBmKOXBDHrx6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "35915be4-cb66-4444-d9b8-e2fa9f0c090f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"an, nor, we, by, all, should've, his, didn, it, above, few, weren't, shouldn't, each, further, you, my, been, those, do, or, will, just, there, her, when, to, for, our, of, are, needn't, so, y, about, while, won't, more, yours, herself, and, don't, ve, in, doing, it's, at, once, not, d, mightn, from, t, you'd, before, most, weren, mightn't, ll, ma, how, am, very, any, itself, can, having, both, only, ain, with, couldn, but, between, should, which, needn, couldn't, they, yourselves, did, haven, same, does, who, were, here, where, during, why, into, don, no, through, she's, themselves, isn, hers, a, being, on, didn't, ourselves, you've, you're, doesn't, shouldn, be, has, theirs, i, hadn't, than, the, over, under, shan, up, shan't, she, hadn, myself, you'll, m, is, own, such, your, that'll, wouldn, if, s, their, out, then, now, below, some, wouldn't, hasn, he, wasn't, have, haven't, o, aren't, him, hasn't, them, what, these, after, as, aren, that, whom, against, other, wasn, won, me, was, until, mustn, himself, its, because, yourself, mustn't, too, off, ours, doesn, again, isn't, re, down, had, this\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "a=nltk.corpus.stopwords.words('english')\n",
        "print(set(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKDn4AnWjKD3",
        "outputId": "fdedfab1-b256-44e5-abe4-a6673c57a0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'an', 'nor', 'we', 'by', 'all', \"should've\", 'his', 'didn', 'it', 'above', 'few', \"weren't\", \"shouldn't\", 'each', 'further', 'you', 'my', 'been', 'those', 'do', 'or', 'will', 'just', 'there', 'her', 'when', 'to', 'for', 'our', 'of', 'are', \"needn't\", 'so', 'y', 'about', 'while', \"won't\", 'more', 'yours', 'herself', 'and', \"don't\", 've', 'in', 'doing', \"it's\", 'at', 'once', 'not', 'd', 'mightn', 'from', 't', \"you'd\", 'before', 'most', 'weren', \"mightn't\", 'll', 'ma', 'how', 'am', 'very', 'any', 'itself', 'can', 'having', 'both', 'only', 'ain', 'with', 'couldn', 'but', 'between', 'should', 'which', 'needn', \"couldn't\", 'they', 'yourselves', 'did', 'haven', 'same', 'does', 'who', 'were', 'here', 'where', 'during', 'why', 'into', 'don', 'no', 'through', \"she's\", 'themselves', 'isn', 'hers', 'a', 'being', 'on', \"didn't\", 'ourselves', \"you've\", \"you're\", \"doesn't\", 'shouldn', 'be', 'has', 'theirs', 'i', \"hadn't\", 'than', 'the', 'over', 'under', 'shan', 'up', \"shan't\", 'she', 'hadn', 'myself', \"you'll\", 'm', 'is', 'own', 'such', 'your', \"that'll\", 'wouldn', 'if', 's', 'their', 'out', 'then', 'now', 'below', 'some', \"wouldn't\", 'hasn', 'he', \"wasn't\", 'have', \"haven't\", 'o', \"aren't\", 'him', \"hasn't\", 'them', 'what', 'these', 'after', 'as', 'aren', 'that', 'whom', 'against', 'other', 'wasn', 'won', 'me', 'was', 'until', 'mustn', 'himself', 'its', 'because', 'yourself', \"mustn't\", 'too', 'off', 'ours', 'doesn', 'again', \"isn't\", 're', 'down', 'had', 'this'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom', 'not']\n",
        "a1=[i for i in a if i not in wh_words]\n",
        "print(a1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEY3rXk2jYsG",
        "outputId": "07d62e18-8ef2-4bb7-9672-93eecd63b8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"how are we putting in efforts to enhance our understanding of Lemmatization\"\n",
        "a2=[i for i in a if i not in sentence]\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeazCaOgkYEk",
        "outputId": "5f045826-8fce-48c6-8212-6e84fb33d560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['me', 'my', 'myself', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'the', 'but', 'if', 'because', 'as', 'until', 'while', 'by', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'from', 'up', 'down', 'out', 'off', 'over', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'll', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
        "stop = set(stopwords.words('english'))\n",
        "sentence = \"how are we putting in efforts to enhance our understanding of Lemmatization\"\n",
        "for word in wh_words:\n",
        "    stop.remove(word)\n",
        "sentence_after_stopword_removal = [token for token in sentence.split() if token not in stop]\n",
        "\" \".join(sentence_after_stopword_removal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MowgS8HnIblC",
        "outputId": "665dfd12-4bea-450f-b73e-d4eb2fd674ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'how putting efforts enhance understanding Lemmatization'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams"
      ],
      "metadata": {
        "id": "KlVSauSzXo9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "text = \"Natural languages are different from computer programming languages\"\n",
        "tokens = text.split()\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "[\" \".join(token) for token in bigrams]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqr2kjSLLw3z",
        "outputId": "c442d621-26c3-482a-feac-be894b2c39ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural languages',\n",
              " 'languages are',\n",
              " 'are different',\n",
              " 'different from',\n",
              " 'from computer',\n",
              " 'computer programming',\n",
              " 'programming languages']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural languages are different from computer programming languages\"\n",
        "tokens = text.split()\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "[\" \".join(token) for token in trigrams]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9UEE9VeZ7RT",
        "outputId": "8c64d871-f568-4abc-e1e6-a0657b5f5b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural languages are',\n",
              " 'languages are different',\n",
              " 'are different from',\n",
              " 'different from computer',\n",
              " 'from computer programming',\n",
              " 'computer programming languages']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **zomato_reviews**"
      ],
      "metadata": {
        "id": "Lcvz6FxzPRzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "9753j-zjM2aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJM3d85dMBOh",
        "outputId": "2a38537d-9218-4ea7-c447-ee8660cd0190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uU-BtBClkwm",
        "outputId": "d748034c-4d49-47d4-d1ba-ff5dfadb9700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/zomato_reviews.csv\")\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Wi9a3CPXIboz",
        "outputId": "77bff7f2-4388-4539-adb6-aa3e222b7d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review sentiment\n",
              "0  Virat Kohli did a great thing to open his rest...  positive\n",
              "1  This place have some really heathy options to ...  positive\n",
              "2  Aerocity is the most finest place in Delhi for...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f62b8b62-7d43-4b83-ab22-f2cf8d51d961\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Virat Kohli did a great thing to open his rest...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This place have some really heathy options to ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aerocity is the most finest place in Delhi for...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f62b8b62-7d43-4b83-ab22-f2cf8d51d961')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f62b8b62-7d43-4b83-ab22-f2cf8d51d961 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f62b8b62-7d43-4b83-ab22-f2cf8d51d961');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = pd.Series(df.Review.tolist()).astype(str)"
      ],
      "metadata": {
        "id": "dS0gl3olRvqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "id": "25LUu1amRwRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1020ef8b-bc35-4139-a066-6bc3945f1833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Virat Kohli did a great thing to open his rest...\n",
              "1       This place have some really heathy options to ...\n",
              "2       Aerocity is the most finest place in Delhi for...\n",
              "3       Yesterday evening there was small team lunch ,...\n",
              "4       I find aerocity to be the best place in delhi ...\n",
              "                              ...                        \n",
              "1591    || DESI LANE || So we were at alipore's most h...\n",
              "1592    \"Desi Lane\" is one of the most trending place ...\n",
              "1593    One of the cool and pocket pinch restaurant at...\n",
              "1594    \"DESI LANE\" one of the best places in town and...\n",
              "1595    Looking for good place for lunch but dont wann...\n",
              "Length: 1596, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Cleaning (Removal of special characters/punctuations & case folding)"
      ],
      "metadata": {
        "id": "WDyrbgvVmBcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_clean(corpus, keep_list):\n",
        "    '''\n",
        "    Purpose : Function to keep only alphabets, digits and certain words (punctuations, qmarks, tabs etc. removed)\n",
        "\n",
        "    Input : Takes a text corpus, 'corpus' to be cleaned along with a list of words, 'keep_list', which have to be retained\n",
        "            even after the cleaning process\n",
        "\n",
        "    Output : Returns the cleaned text corpus\n",
        "\n",
        "    '''\n",
        "    cleaned_corpus = pd.Series()\n",
        "    for row in corpus:\n",
        "        qs = []\n",
        "        for word in row.split():\n",
        "            if word not in keep_list:\n",
        "                p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=word)\n",
        "                p1 = p1.lower()\n",
        "                qs.append(p1)\n",
        "            else : qs.append(word)\n",
        "        cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
        "    return cleaned_corpus"
      ],
      "metadata": {
        "id": "S-f7OxJwR4S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stopwords_removal(corpus):\n",
        "    wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
        "    stop = set(stopwords.words('english'))\n",
        "    for word in wh_words:\n",
        "        stop.remove(word)\n",
        "    corpus = [[x for x in x.split() if x not in stop] for x in corpus]\n",
        "    return corpus"
      ],
      "metadata": {
        "id": "bf9e4UgaSBCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize(corpus):\n",
        "    lem = WordNetLemmatizer()\n",
        "    corpus = [[lem.lemmatize(x) for x in x] for x in corpus]\n",
        "    return corpus"
      ],
      "metadata": {
        "id": "T-hAwz_5pCgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/zomato_reviews.csv\")\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "VDYUNggzsBSU",
        "outputId": "521895e2-06b3-4257-c3c9-88b0e120534e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review sentiment\n",
              "0  Virat Kohli did a great thing to open his rest...  positive\n",
              "1  This place have some really heathy options to ...  positive\n",
              "2  Aerocity is the most finest place in Delhi for...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71cae25f-a6f3-45d7-83e3-82b0e6c0aa3a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Virat Kohli did a great thing to open his rest...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This place have some really heathy options to ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aerocity is the most finest place in Delhi for...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71cae25f-a6f3-45d7-83e3-82b0e6c0aa3a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71cae25f-a6f3-45d7-83e3-82b0e6c0aa3a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71cae25f-a6f3-45d7-83e3-82b0e6c0aa3a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_with_lemmatization = preprocess(a1[0], keep_list = common_dot_words, stemming = False, stem_type = None, lemmatization = True, remove_stopwords = False)\n",
        "print(corpus_with_lemmatization)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "LxFxJIA_rlIU",
        "outputId": "9e9a5fdc-cdca-4939-cc30-79745a8293ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-bb757a8505d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus_with_lemmatization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_dot_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstemming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstem_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_stopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_with_lemmatization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocess' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original string: \", corpus[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHPr5h7YqeCq",
        "outputId": "f92db401-b90d-41a3-abcf-0673c96cff89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original string:  Aerocity is the most finest place in Delhi for luxury dining as the place is too clean and it's a place with good view. I went to this restaurant Yesterday and it was all over a great Experience over there. We had Veg Pizza Mocktails Shakes Andhra paneer Mock meat platter Chocolate brownie Cheese cake The taste was very delicious and good the food presentation was also appreciable and the staff also very cooperative and helpful. And the outdoor sitting space is too good as it gives an amazing view.\n"
          ]
        }
      ]
    }
  ]
}